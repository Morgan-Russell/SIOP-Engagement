# Analyses

![](results.jpg)

bifactor analysis are most commonly applied in the exploration of common method variance [see, for example, @reise_rediscovery_2012;  @rodriguez_evaluating_2016]. @giordano_exploratory_2020 provide an overview regarding past and potential applications of *exploratory* bifactor analysis and cite @reise_rediscovery_2012 as an influential impetus for the resurgence of bifactor models in general. 

```{r data, echo=FALSE, warning=FALSE, message=FALSE}

temp <- read.csv("qualtrics_pilot_data.csv", header=FALSE, na.strings="")

x <- temp[2,]
data <- temp[-c(1:3),]
colnames(data) <- x

num <- nrow(data)

## getting conditions into one large file below - 12/9/20

data$Cond1 <- rowSums(is.na(data[18:53]))
data$Cond2 <- rowSums(is.na(data[54:89]))
data$Cond3 <- rowSums(is.na(data[90:125]))
data$Cond4 <- rowSums(is.na(data[126:161]))

data$Condition[data$Cond1 < 36] <- 1
data$Condition[data$Cond2 < 36] <- 2
data$Condition[data$Cond3 < 36] <- 3
data$Condition[data$Cond4 < 36] <- 4

cond1 <- data[ which(data$Condition==1), ]
cond2 <- data[ which(data$Condition==2), ]
cond3 <- data[ which(data$Condition==3), ]
cond4 <- data[ which(data$Condition==4), ]

cond1.red <- cond1[,c(6, 18:53, 162:165, 171)]  ## using Cond1 ordering
cond2.red <- cond2[,c(6, 62:65, 70:73, 82:85, 58:61, 74:77, 86:89, 66:69, 78:81, 54:57, 162:165, 171)]
cond3.red <- cond3[,c(6, 94:97, 106:109, 118:121, 98:101, 110:113, 122:125, 102:105, 114:117, 90:93, 162:165, 171)]
cond4.red <- cond4[,c(6, 138:161, 130:137, 126:129, 162:165, 171)]        ## 171 versus 172 because testing script has extra "hours" variable

names(cond1.red) = gsub(pattern = "C*.* - ", replacement = "", x = names(cond1.red))      ## Getting rid of condition markers so rbind will work
names(cond2.red) = gsub(pattern = "C*.* - ", replacement = "", x = names(cond2.red))  
names(cond3.red) = gsub(pattern = "C*.* - ", replacement = "", x = names(cond3.red))  
names(cond4.red) = gsub(pattern = "C*.* - ", replacement = "", x = names(cond4.red))  

together <- rbind(cond1.red, cond2.red, cond3.red, cond4.red)        ## we'll be using this object for analyses

num_valid <- nrow(together)

i <- c(1:37)                                          ## Changing item responses to numerics
together[ , i] <- apply(together[ , i], 2,            # Specify own function within apply
                    function(x) as.numeric(as.character(x)))

library(descr)
freq(together$`Duration (in seconds)`)

```

## Pilot analyses

`r num_valid` people responded. Probably need to further screen for duration. This is the number of seconds to complete the entire survey (according to communications with Qualtrics in early December). It looks like our "number of people who clicked on the assessment link (`r num`)" versus valid *n* (`r num_valid`) took care of our very low duration respondents. The lowest in the `r num` datafile is `r min(data$Duration)` whereas the lowest in the `r num_valid` datafile is `r min(together$Duration)`.

### Classical test theory

+ corrected item-total correlations and alphas by condition


```{r alphas, echo=FALSE, warning=FALSE, message=FALSE}

## recodes 12/9/20

## AFFECTIVE: 

together$`Most days, I feel happiest when the workday is soon to be complete.` <- 7 - together$`Most days, I feel happiest when the workday is soon to be complete.`
together$`This job drains my energy.` <- 7 - together$`This job drains my energy.`

## BEHAVIORAL (NONE):

## COGNITIVE: 

together$`Thinking about work saps my energy.` <- 7 - together$`Thinking about work saps my energy.`
together$`I often think about finding another job.` <- 7 - together$`I often think about finding another job.`


affect <- psych::alpha(together[2:13])  
behave <- psych::alpha(together[14:25])
cogni <- psych::alpha(together[26:37])

absorb <- psych::alpha(together[c(2:5, 14:17, 34:37)])  
vigor <- psych::alpha(together[c(26:29, 6:9, 18:21)])
dedic <- psych::alpha(together[c(30:33, 10:13, 22:25)])


```

#### Internal consistency estimates

| Dimension      | Alpha                                   |
|----------------|-----------------------------------------|
| Affective      | `r round(affect$total$raw_alpha, 2)`    |
| Behavioral     | `r round(behave$total$raw_alpha, 2)`    |
| Cognitive      | `r round(cogni$total$raw_alpha, 2)`     |
|                |                                         |
| Absorption     | `r round(absorb$total$raw_alpha, 2)`    |
| Vigor          | `r round(vigor$total$raw_alpha, 2)`     |
| Dedication     | `r round(dedic$total$raw_alpha, 2)`     |

Corrected item-total correlations:

```{r rdrops, echo=FALSE, warning=FALSE, message=FALSE}

library(kableExtra)
kable(affect$item.stats[-c(2:4)], digits=2, caption="Affective Items")
kable(behave$item.stats[-c(2:4)], digits=2, caption="Behavioral Items")
kable(cogni$item.stats[-c(2:4)], digits=2, caption="Cognitive Items")
kable(absorb$item.stats[-c(2:4)], digits=2, caption="Absorption Items")
kable(vigor$item.stats[-c(2:4)], digits=2, caption="Vigor Items")
kable(dedic$item.stats[-c(2:4)], digits=2, caption="Dedication Items")

```


### Confirmatory factor analyses

#### Multigroup analyses

+ using experimental condition as "multiple groups" (measurement invariance)

#### Bifactor analyses

+ looking at dual structure

### Summary

Recommendation for final instrument based on consideration of all of the above pieces of evidence

## Construct and Criterion-related Validation

Use Gallup for construct validation [@thackray_gallup_2005; @harter_relationship_2013]. Also the Utrecht Work Engagement Scale [UWES; @schaufeli_measurement_2002; @schaufeli_defining_2010]
